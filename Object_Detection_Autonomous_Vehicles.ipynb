{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmK1Tq9CCIxJ8WGGnt+zDv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4nuFfAiwj9v"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "import torchvision as tv\n",
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checklist\n",
        "\n",
        "is_gpu_available = t.cuda.is_available()\n",
        "\n",
        "if (is_gpu_available):\n",
        "  print(\"cuda available, ok to proceed\")\n",
        "else:\n",
        "  raise Exception(\"cuda unavailable, cannot proceed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0apFC-_FyODq",
        "outputId": "1b6d01bb-d9f9-4ff7-c60b-9062ad047983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available, ok to proceed\n"
          ]
        }
      ]
    }
  ]
}